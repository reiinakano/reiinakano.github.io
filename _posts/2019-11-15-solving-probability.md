---
layout: post
title:  "Teaching a neural network to use a calculator"
image: 
  path: "images/rnst/banner.jpg"
  thumbnail: "images/rnst/banner.jpg"
  hide: true
date:   2019-11-01
excerpt: Teaching a neural network to solve simple probability problems step by step with an external symbolic solver.
---



### The data/Generating intermediate steps


### The model/Using an external symbolic solver


### Results


### Analysis of Results

success and failure cases, especially extrapolation failure (broken clock right twice a day, no "understanding")

### Examining the data distribution


### Equivalent solutions

found using beam search

### Visualizing attention


### Related Literature


### Conclusions and future work


### Acknowledgments


### Citation

If you found this work useful, please cite it as:

```
```

[^1]: Adversarial examples are inputs that are specially crafted by an attacker to trick a classifier into producing an incorrect label for that input. There is an entire field of research dedicated to adversarial attacks and defenses in deep learning literature.


[google_colab]: https://colab.research.google.com/
